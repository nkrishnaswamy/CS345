# CS 345 fall 2020

Content for the fall 2020 offering of CS 345


The notebooks for this course are divided into the following modules:

### Table of Contents

* Introduction to machine learning, the Python tools we will use, and mathematical background
  * [Introduction to machine learning and the Jupyter notebook](notebooks/module01_01_intro.ipynb)
  * [Labeled data and supervised learning](notebooks/module01_02_labeled_data.ipynb)
  * [NumPy](notebooks/module01_03_numpy.ipynb)
  * [Vectors and dot products](notebooks/module01_04_vectors_dot_products.ipynb)
  * [Visualizing data with Matplotlib](notebooks/module01_05_matplotlib.ipynb)
* Our first classifiers:  the perceptron and nearest neighbors
  * [Hyperplanes](notebooks/module02_01_hyperplanes.ipynb)
  * [Matrices](notebooks/module02_02_matrices.ipynb)
  * [The perceptron](notebooks/module02_03_perceptron.ipynb)
  * [Nearest neighbor classification](notebooks/module02_04_nearest_neighbors.ipynb)
  * [Nearest neighbor classification (part 2)](notebooks/module02_05_more_nearest_neighbors.ipynb)
* Linear regression
  * [Introduction to linear regression](notebooks/module03_01_linear_regression.ipynb)
  * [Derivatives and partial derivatives](notebooks/module03_02_derivatives_partial_derivatives.ipynb)
  * [Multivariate linear regression](notebooks/module03_03_multivariate_linear_regression.ipynb)
  * [Solving linear regression with gradient descent](notebooks/module03_04_linear_regression_gradient_descent.ipynb)
* Overfitting and regularization
  * [Basis function regression and overfitting](notebooks/module04_01_overfitting_basis_function_regression.ipynb)
  * [Regularization](notebooks/module04_02_regularization.ipynb)
* Classifier evaluation
  * [Cross-validation](notebooks/module05_01_cross_validation.ipynb)
  * [Measuring classifier accuracy](notebooks/module05_02_classifier_accuracy.ipynb)
  * [ Model selection](notebooks/module05_03_model_selection.ipynb)
* Decision trees, ensemble methods, and random forests  
  * [Decision trees](module06_01_decision_trees.ipynb)
  * [Ensemble methods and random forests](module06_02_ensemble_methods.ipynb)
* Towards neural networks:  Logistic regression
  * [A primer in probability](notebooks/module07_01_probability.ipynb)
  * [Logistic regression](notebooks/module07_02_logistic_regression.ipynb)
  * [Regularization revisited](notebooks/module07_03_regularization_revisited.ipynb)
* Neural networks
  * [An introduction to feed forward networks](notebooks/module08_01_neural_networks_mlp.ipynb)
  * [Feed forward networks using keras](notebooks/module08_02_neural_networks_keras.ipynb)
  * [Image classification using feed forward neural networks](notebooks/module08_03_neural_networks_mnist.ipynb)
* Naive Bayes
  * [Text classification with Naive Bayes](notebooks/module09_01_naive_bayes.ipynb)
* Conclusions
    * [A summary of supervised learning](notebooks/module10_01_conclusions.ipynb)

* Appendix:  a brief introduction to Python [ [notebook](notebooks/module0_01_python_intro.ipynb) ]
